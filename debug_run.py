import pickle
import numpy as np
import torch
import utils
import model
from parameters import *

print("üöÄ DEBUG RUN STARTED")

# =========================================================
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ –¥–∞–Ω–Ω–∏ (–∞–∫–æ –æ—â–µ –Ω–µ —Å–∞ –ø–æ–¥–≥–æ—Ç–≤–µ–Ω–∏)
# =========================================================
try:
    trainCorpus, devCorpus = pickle.load(open(corpusFileName, 'rb'))
    word2ind = pickle.load(open(wordsFileName, 'rb'))
    print("‚úÖ –î–∞–Ω–Ω–∏—Ç–µ –≤–µ—á–µ —Å–∞ –ø–æ–¥–≥–æ—Ç–≤–µ–Ω–∏")
except:
    print("üì¶ –ü–æ–¥–≥–æ—Ç–≤—è–º –¥–∞–Ω–Ω–∏—Ç–µ...")
    trainCorpus, devCorpus, word2ind = utils.prepareData(
        sourceFileName, targetFileName,
        sourceDevFileName, targetDevFileName,
        '<S>', '</S>', '<UNK>', '<PAD>', '<TRANS>'
    )
    trainCorpus = [[word2ind.get(w, 2) for w in s] for s in trainCorpus]
    devCorpus = [[word2ind.get(w, 2) for w in s] for s in devCorpus]
    pickle.dump((trainCorpus, devCorpus), open(corpusFileName, 'wb'))
    pickle.dump(word2ind, open(wordsFileName, 'wb'))
    print("‚úÖ –î–∞–Ω–Ω–∏—Ç–µ —Å–∞ –∑–∞–ø–∏—Å–∞–Ω–∏")

# =========================================================
# 2. –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞
# =========================================================
print("üß† –°—ä–∑–¥–∞–≤–∞–º –º–æ–¥–µ–ª–∞...")

nmt = model.LanguageModel(
    vocab_size=len(word2ind),
    emb_dim=emb_dim,
    hidden_dim=hidden_dim,
    num_layers=num_layers,
    start_idx=0,
    end_idx=1,
    pad_idx=3,
    trans_idx=4
).to(device)

optimizer = torch.optim.Adam(nmt.parameters(), lr=learning_rate)

# =========================================================
# 3. –ú–∞–ª–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∞ —Å—Ç—ä–ø–∫–∞ (—Ç–µ—Å—Ç)
# =========================================================
print("üèãÔ∏è –¢–µ—Å—Ç–æ–≤–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞...")

nmt.train()
idx = np.arange(len(trainCorpus))
np.random.shuffle(idx)

batch = [trainCorpus[i] for i in idx[:batchSize]]
loss = nmt(batch)

optimizer.zero_grad()
loss.backward()
optimizer.step()

print("‚úÖ Loss:", loss.item())

# =========================================================
# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ generate()
# =========================================================
print("üîÆ –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ...")

test_sentence = trainCorpus[0][:5]  # –ø—ä—Ä–≤–∏—Ç–µ –Ω—è–∫–æ–ª–∫–æ —Ç–æ–∫–µ–Ω–∞
print("Input indices:", test_sentence)

nmt.eval()
with torch.no_grad():
    result = nmt.generate(test_sentence)

print("Generated indices:", result)

print("üéâ –í–°–ò–ß–ö–û –†–ê–ë–û–¢–ò")
